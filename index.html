<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Sofia</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Sofia">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Sofia">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Sofia">
  
    <link rel="alternate" href="/atom.xml" title="Sofia" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Sofia</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Buscar"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-搭建博客" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/28/搭建博客/" class="article-date">
  <time datetime="2018-01-27T16:46:35.931Z" itemprop="datePublished">2018-01-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/28/搭建博客/">创建博客</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="欢迎找我讨论，我遇到了很多问题，可能对你有帮助"><a href="#欢迎找我讨论，我遇到了很多问题，可能对你有帮助" class="headerlink" title="欢迎找我讨论，我遇到了很多问题，可能对你有帮助"></a>欢迎找我讨论，我遇到了很多问题，可能对你有帮助</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">推荐参考：</span><br></pre></td></tr></table></figure>
<p>请点击这里：<a href="https://www.jianshu.com/p/189fd945f38f" target="_blank" rel="noopener">参考</a></p>
<h2 id="关于报错"><a href="#关于报错" class="headerlink" title="关于报错"></a>关于报错</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">请一定要看报错内容，有时候会提示你如何让进行操作。</span><br></pre></td></tr></table></figure>
<h2 id="关于我认为最难的如何安装hexo的参考文章"><a href="#关于我认为最难的如何安装hexo的参考文章" class="headerlink" title="关于我认为最难的如何安装hexo的参考文章"></a>关于我认为最难的如何安装hexo的参考文章</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">推荐参考：</span><br></pre></td></tr></table></figure>
<p>请点击这里：<a href="http://blog.csdn.net/xuezhisdc/article/details/53130328" target="_blank" rel="noopener">参考</a></p>
<h2 id="私人建议"><a href="#私人建议" class="headerlink" title="私人建议"></a>私人建议</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">文章的写法可以参照hello-world.md</span><br><span class="line">Hexo 文件在OS(C:)会比较容易成功</span><br><span class="line">注意<span class="string">"："</span>后面的一个空格</span><br><span class="line">请使用英文的：</span><br><span class="line">以及Notepad++可以编辑md文件</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/01/28/搭建博客/" data-id="cjf9r55ik0000e8v2ey9ah0wp" class="article-share-link">Compartir</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-关于python的词频统计" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/10/关于python的词频统计/" class="article-date">
  <time datetime="2017-12-10T09:10:03.728Z" itemprop="datePublished">2017-12-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/10/关于python的词频统计/">关于python的词频统计</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="常用常识点"><a href="#常用常识点" class="headerlink" title="常用常识点"></a>常用常识点</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">进入到powershell下键入：Get-Content d:\temp\语料.txt -totalcount x1，来查看文件的前x1行。</span><br><span class="line">对于(非京/ns   籍/ng )格式中的词的取法：words = [word.split(<span class="string">'/'</span>)[0] <span class="keyword">for</span> word <span class="keyword">in</span> text.split()]</span><br><span class="line">统计字符串频次的方法：字符串.count(str)，参数也是字符串，功能是在字符串对象中统计参数字符串出现的频次，返回一个整型数。</span><br><span class="line">用<span class="keyword">for</span> line <span class="keyword">in</span> f:逐行读入可以避免读入文件的内存溢出</span><br><span class="line">测试运行时间可能遇到:f.seek(0):f.seek(int)方法能够回到文件对象f的指定字节位置，如果参数是0，则回到文件的起始位置。</span><br><span class="line">time模块的time.time():time()函数能够把当前时间转化为秒，返回浮点数</span><br><span class="line">sort()是python的list对象的快速排序方法，用法是：列表.sort()，可将列表中的元素进行排序(默认为正序)。注意，列表自身进行了排序。</span><br><span class="line">sorted(...)是python内置的快速排序方法，用法是：sorted(seq)，可返回对序列seq排序后新生成的一个列表。注意，原有序列不变。</span><br><span class="line">bisect.bisect_left()方法能够直接找到插入位置，因此每次插入新对象后，词表仍然可以保持有序。这也是一种排序算法，即二分插入排序.</span><br><span class="line">seq[::-1]可以实现字符串的反转。</span><br></pre></td></tr></table></figure>
<h2 id="关于提升效率"><a href="#关于提升效率" class="headerlink" title="关于提升效率"></a>关于提升效率</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在统计词频时，将文件内所有词遍历再与已经得到的部分统计结果(类似词语 次数的部分表单)进行对比从而得到结果是十分缓慢的。(真的很慢，不信可以试试)</span><br><span class="line">利用二分插入排序能够相比而言更加高效的找到插入位置提升速度，但是还不够。</span><br><span class="line">散列/哈希思想能够有极好的提高效率，使你的代码能够真正的高逼格起来，能够投入应用。</span><br><span class="line">根据散列/哈希思想，python中内置实现了集合<span class="built_in">set</span>与词典dict。</span><br><span class="line">(dict的性能其实已经足够)</span><br></pre></td></tr></table></figure>
<h2 id="两种效率较高的写法"><a href="#两种效率较高的写法" class="headerlink" title="两种效率较高的写法"></a>两种效率较高的写法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from collections import defaultdict</span><br><span class="line"></span><br><span class="line">def count_words_freq_dict(filename):</span><br><span class="line">    words_freq_dict = defaultdict(int)</span><br><span class="line">    </span><br><span class="line">    with open(filename) as f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            words = [word.split(<span class="string">'/'</span>)[0] <span class="keyword">for</span> word <span class="keyword">in</span> line.split()]</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">                words_freq_dict[word] += 1    </span><br><span class="line">    <span class="built_in">return</span> words_freq_dict</span><br><span class="line">——————————————————————————————————————————————</span><br><span class="line">from collections import Counter(较优)</span><br><span class="line"></span><br><span class="line">def count_words_freq_dict(filename):</span><br><span class="line">    words_freq_dict = Counter()</span><br><span class="line">    </span><br><span class="line">    with open(filename) as f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            words_freq_dict.update([word.split(<span class="string">'/'</span>)[0] <span class="keyword">for</span> word <span class="keyword">in</span> line.split()])</span><br><span class="line">    <span class="built_in">return</span> words_freq_dict</span><br></pre></td></tr></table></figure>
<h2 id="在统计词频的基础上统计字频-效率会更高"><a href="#在统计词频的基础上统计字频-效率会更高" class="headerlink" title="在统计词频的基础上统计字频(效率会更高)"></a>在统计词频的基础上统计字频(效率会更高)</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from collections import defaultdict</span><br><span class="line">ch_table = defaultdict(int)</span><br><span class="line"><span class="keyword">for</span> word, freq <span class="keyword">in</span> word_table.items():</span><br><span class="line">    <span class="keyword">for</span> ch <span class="keyword">in</span> word:</span><br><span class="line">        ch_table[ch] += freq</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/12/10/关于python的词频统计/" data-id="cjf9r55jn0002e8v2qipz1e8l" class="article-share-link">Compartir</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-python爬虫" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/04/03/python爬虫/" class="article-date">
  <time datetime="2017-04-03T00:34:14.808Z" itemprop="datePublished">2017-04-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/04/03/python爬虫/">python爬虫</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="什么是爬虫"><a href="#什么是爬虫" class="headerlink" title="什么是爬虫"></a>什么是爬虫</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">爬虫就是一段能够获取互联网信息（数据）的程序。</span><br><span class="line">一般通过抓取网页获取互联网的信息与数据。</span><br><span class="line">爬虫是获得网页的文本文件并进行解析。</span><br><span class="line">如果数据在文本文件中，可以直接得到，如果在网页外部，则通过解析的结果得到数据所在地址，将该数据下载。</span><br></pre></td></tr></table></figure>
<h2 id="最简爬虫"><a href="#最简爬虫" class="headerlink" title="最简爬虫"></a>最简爬虫</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python的第三方库requests。</span><br><span class="line">该库完全符合python的设计理念，利于理解和使用。</span><br><span class="line">导入必要的模块：</span><br><span class="line">	import requests</span><br><span class="line">	from bs4 import BeautifullSoup</span><br><span class="line">	import re</span><br></pre></td></tr></table></figure>
<h2 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">'https://github.com/liupengyuan/python_tutorial/blob/master/chapter1/0.md'</span>)</span><br><span class="line"><span class="built_in">print</span>(r.text[:1000])</span><br><span class="line">发送获取(get)请求，该方法返回一个应答(Response)对象r，其中包含该网页的所有信息。</span><br><span class="line"><span class="built_in">print</span>(r.text[:1000])，利用对象r的text属性字符串，打印网页内容，因为内容较多，暂取前1000个字符。</span><br><span class="line">后续由于需要用到Chrome浏览器中的检查功能，因此需要下载安装Chrome浏览器。</span><br><span class="line">通过谷歌浏览器的右键，检查，可以找到要爬的东西在HTML文本文件中的位置。</span><br></pre></td></tr></table></figure>
<h2 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">这里我们将介绍一个优秀的第三方网页解析包：Beautifulsoap。该包已经随Anaconda安装，名称为bs4。可以用这个包(必要时联合正则表达式)来进行网页解析。</span><br><span class="line">该包已经通过from bs4 import BeautifulSoup在开始导入</span><br><span class="line">soup = BeautifulSoup(r.text, <span class="string">'html.parser'</span>)</span><br><span class="line">contents = soup.find_all(<span class="string">'ul'</span>, attrs=<span class="string">'cm_ul_round'</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'type is:'</span>, <span class="built_in">type</span>(contents))</span><br><span class="line">contents[:1]</span><br><span class="line"></span><br><span class="line">函数BeautifulSoup(r.text, <span class="string">'html.parser'</span>)，返回一个BeautifulSoup对象。</span><br><span class="line">第一个参数为要解析的网页文本，第二个参数是解析器的选择，暂选择python内置的<span class="string">'html.parser'</span>作为解析器。</span><br><span class="line">soup.find_all(<span class="string">'ul'</span>, attrs=<span class="string">'cm_ul_round'</span>)，BeautifulSoup对象的方法，可返回指定标签之间的所有内容的ResultSet对象。</span><br><span class="line">其中第一个参数为标签，第二个参数为标签的属性。</span><br><span class="line">根据新闻标题，在Elements标签页面稍加分析可知：新闻标题及链接均在标签对&lt;ul class=<span class="string">"cm_ul_round"</span>&gt;及&lt;/ul&gt;之间，且其他非新闻标题的内容，均不在这种规定了class的&lt;ul&gt;标签之间</span><br></pre></td></tr></table></figure>
<h2 id="例子3"><a href="#例子3" class="headerlink" title="例子3"></a>例子3</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> contents:</span><br><span class="line">    url_titles = line.find_all(<span class="string">'a'</span>)</span><br><span class="line">    <span class="keyword">for</span> url_title <span class="keyword">in</span> url_titles:</span><br><span class="line">        url = url_title.get(<span class="string">'href'</span>)</span><br><span class="line">        title = url_title.string</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">type</span>(url_title), url, title)</span><br><span class="line">    <span class="keyword">if</span> input()==<span class="string">'b'</span>:</span><br><span class="line">        <span class="built_in">break</span></span><br><span class="line">利用line.find_all(<span class="string">'a'</span>)取得其中在&lt;a&gt;及&lt;/a&gt;标签对(该标签对表示超链接)。</span><br><span class="line">对url_titles进行遍历，每一个对象均为Tag对象，利用Tag对象的get(<span class="string">'href'</span>)方法，该方法可以取得标签的属性值，本例中参数为属性href，其值为超链接的URL</span><br><span class="line">利用标签的string属性，取得该超链接的文本</span><br><span class="line">可以用字典来储存抓取的文字</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/04/03/python爬虫/" data-id="cjf9r55ir0001e8v2b2dhxoui" class="article-share-link">Compartir</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archivos</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Posts recientes</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/01/28/搭建博客/">创建博客</a>
          </li>
        
          <li>
            <a href="/2017/12/10/关于python的词频统计/">关于python的词频统计</a>
          </li>
        
          <li>
            <a href="/2017/04/03/python爬虫/">python爬虫</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Still Sofia<br>
      Construido por <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>